---
title: "Data integration investigation"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
header-includes:
  - \usepackage{setspace}\doublespacing
  - \usepackage{mdframed, caption}
  - \usepackage[linesnumbered,lined,boxed,commentsnumbered]{algorithm2e}
  - \usepackage{float}
  - \floatplacement{figure}{H} 
  - \usepackage{longtable}
  - \usepackage{blkarray, bigstrut}
  - \usepackage{booktabs}
  - \usepackage{multirow}
bibliography: bibliography.bib
csl: biometrics_notes.csl
---

```{r, eval = F}
library(nimble)

X <- cbind(
  rep(1, 100),
  rnorm(100)
)
y <- c(X %*% matrix(c(2, 1), ncol = 1) + rnorm(100))

# function to fit model
fit_model <- function(seed = 1, code, data, constants, inits, niter, nchains, thin = 1, nburnin = 0){
  library(nimble)
  
  # some functions
  # R model
  model <- nimbleModel(code, constants, data)
  
  # C model
  model_c <- compileNimble(model)
  
  # R mcmc
  model_conf <- configureMCMC(model)
  
  # R mcmc
  mcmc <- buildMCMC(model_conf)
  
  # C mcmc
  mcmc_c <- compileNimble(mcmc, project = model_c)
  
  # run model
  out <- runMCMC(
    mcmc_c, 
    niter = niter, 
    nchains = nchains, 
    thin = thin, 
    init = inits,
    setSeed = seed,
    nburnin = nburnin
  )
  
  # out
  return(out)
}

code <- nimbleCode({
  for(i in 1:2){
    beta[i] ~ dnorm(0, sd = 100)
  }
  sigma ~ T(dnorm(0, var = 100), 0, Inf)
  
  for(i in 1:n){
    mu[i] <- (beta[1:2] %*% X[i, 1:2])[1,1]
    y[i] ~ dnorm(mu[i], sd = sigma)
  }
})

init_func <- function(){
  out <- list(
    beta = rnorm(2),
    sigma = rgamma(1, 1, 1)
  )
  
  return(out)
}

fit <- fit_model(
  seed = 1:3,
  code = code,
  data = list(
    # response
    y = y
  ),
  constants = list(
    n = 100,
    X = X
  ),
  niter = 5000,
  nchains = 3,
  thin = 1,
  nburnin = 0,
  inits = init_func
)
```

\newpage 

```{r setup, include = F}
rm(list = ls())

library(knitr)
hook_chunk <- knitr::knit_hooks$get('chunk')
knit_hooks$set(chunk = function(x, options) {

  # add latex commands if chunk option singlespacing is TRUE
  if(isTRUE(options$singlespacing)){
    return(sprintf("\\singlespacing\n %s \n\\doublespacing", hook_chunk(x, options)))
  } else{
    return(hook_chunk(x, options))
  }
})
knitr::opts_chunk$set(
  fig.align = "center",
  tidy = T,
  singlespacing = TRUE,
  cache = FALSE,
  fig.dim = c(10,8),
  message = FALSE,
  warning = FALSE,
  comment = NA,
  echo = F
)


# packages
packs <- c("dplyr", "nimble", "htmltools", "ggplot2", "sf", "Rcpp", "RcppArmadillo", "inline", "mvtnorm", "readr", "parallel", "xtable", "rstan", "coda", "vegan", "tidyr", "gganimate", "stringr", "scatterplot3d", "plot3D", "plotly", "tidyverse", "ggalluvial", "lubridate", "ggnewscale")
sapply(packs, require, character.only = T)
rm(packs)
options(tidyverse.quiet = TRUE)

# convenience
`%notin%` <- Negate("%in%")

# stan settings
options(mc.cores = parallel::detectCores() - 1)
rstan_options(auto_write = TRUE)
```

# Introduction

# Univariate normal

Sampling model:

\[
y_i \sim N(\mu, \sigma^2)
\]

Priors:

\[
\begin{split}
\mu &\sim N(\mu_0, \tau_0^2) \\
\sigma &\sim IG(a_0, b_0)
\end{split}
\]

## Simulated data

```{r}
sim_norm <- function(n, mu, sigma, seed = NULL){
  if(!is.null(seed)) set.seed(seed)
  y <- rnorm(n, mu, sigma)
  return(y)
}
y <- sim_norm(500, 0, 2, seed = 05172022)
ggplot() + 
  geom_histogram(data = tibble(y = y), aes(x = y)) +
  theme_bw() +
  labs(title = "Simulated data, mu = 0, sigma = 2")
```

## Gibbs sampler

```{r}
# num_mcmc = 5000
# seed = 05172022
normal_gibbs <- function(num_mcmc, warmup = num_mcmc/2, y, seed = NULL){
  
  if(!is.null(seed)) set.seed(seed)
  
  # convenience
  n <- length(y)
  sum_y <- sum(y)
  
  # storage
  mu_mcmc <- matrix(NA, num_mcmc, 1)
  sigma_mcmc <- matrix(NA, num_mcmc, 1)
  
  # priors
  mu0 <- 0
  tau0 <- 100
  a0 <- .01
  b0 <- .01
  
  # initialize
  mu <- rnorm(1, mu0, tau0); mu_mcmc[1,] <- mu
  sigma <- invgamma::rinvgamma(1, a0, b0); sigma_mcmc[1,] <- sigma
  
  # sampler
  pb <- txtProgressBar(min = 0, max = num_mcmc, style = 3, width = 50, char = "=") 
  for(iter in 2:num_mcmc){
    # mu
    v <- solve(1/tau0^2 + n/sigma^2)
    m <- v * (mu0 / tau0^2 + sum_y / sigma^2)
    mu <- rnorm(1, m, sqrt(v))
    
    # sigma
    a <- a0 + n/2
    b <- b0 + sum((y-mu)^2)/2
    sigma <- sqrt(invgamma::rinvgamma(1, a, b))
    
    # storage
    mu_mcmc[iter,] <- mu
    sigma_mcmc[iter,] <- sigma
    
    # progress
    setTxtProgressBar(pb, iter)
  }
  close(pb)
  
  samples <- list(
    mu = mu_mcmc[(warmup+1):num_mcmc,],
    sigma = sigma_mcmc[(warmup+1):num_mcmc,]
  )
  
  return(samples)
  
}

samples <- normal_gibbs(num_mcmc = 5000, y = y, seed = 05172022)
```

```{r, echo = T}
mean(samples$mu)
mean(samples$sigma)
```

# Multivariate normal 

```{r}
nimble_summary <- function(fit, warmup = nrow(fit[[1]])/2, thin = 1){
  # convert to coda for normal summary
  fit_warmup <- lapply(fit, function(x) x[(warmup+1):nrow(x),])
  coda_samples <- as.mcmc.list(lapply(fit_warmup, function(x) as.mcmc(
    x, start = warmup+1, end = nrow(fit), thin = thin
  )))
  
  sum <- summary(coda_samples)
  params <- dimnames(sum$statistics)[[1]]
  tmp_sum <- cbind(sum$statistics, sum$quantiles)
  
  # get r hat / n_eff
  mat <- matrix(NA, nrow = nrow(tmp_sum), ncol = 3)
  colnames(mat) <- c("Rhat", "ess_bulk", "ess_tail")
  for(i in 1:nrow(tmp_sum)){
    tmp <- sapply(fit, function(x) x[,i])
    mat[i,] <- c(Rhat(tmp), ess_bulk(tmp), ess_tail(tmp))
  }
  
  # out 
  out <- cbind(tmp_sum, mat)
  return(out)
}

sim_reg <- function(n, beta, X, sigma, Omega = diag(n), seed = NULL){
  if(!is.null(seed)) set.seed(seed)
  
  mu <- X %*% beta
  Sigma <- sigma^2 * Omega + diag(.00001, n, n)
  # y <- chol(Sigma) %*% rnorm(n) + mu
  y <- c(mvtnorm::rmvnorm(1, mu, Sigma))
  
  df <- cbind(
    y,
    X[,2:ncol(X), drop=FALSE]
  ) %>%
    as_tibble
  
  names(df)[2:ncol(df)] <- paste0("x", 1:(ncol(X)-1))

  return(
    df
  )
}
```

## Ordinary least squares regression

\[
\begin{split}
\boldsymbol{y} \sim \mathcal{N}(X\boldsymbol{\beta}, \sigma^2 \boldsymbol{I}_n)
\end{split}
\]

### Simulated data

```{r}
n <- 500
y <- sim_reg(
  n = n, 
  X = matrix(1, nrow = n),
  beta = 0,
  sigma = 2, 
  Omega = diag(n),
  seed = 05172022
)
ggplot() + 
  geom_histogram(data = tibble(y = y), aes(x = y)) +
  theme_bw() +
  labs(title = "Simulated data, beta = 0, sigma = 2, Omega = diag(n)")
```

### Gibbs sampler

```{r}
# num_mcmc = 5000
# seed = 05172022
# Omega = diag(nrow(y))
# X = matrix(1, nrow = n)
ols_gibbs <- function(num_mcmc, warmup = num_mcmc/2, y, X_, Omega, seed = NULL){
  
  if(!is.null(seed)) set.seed(seed)
  
  # convenience
  n <- nrow(X_)
  p <- ncol(X_)
  
  # storage
  sigma_mcmc <- matrix(NA, num_mcmc, 1)
  beta_mcmc <- matrix(NA, num_mcmc, p)
  
  # priors
  mu0 <- matrix(0, nrow = p, ncol = 1)
  Sigma0 <- matrix(1000, nrow = p, ncol = p)
  Sigma0_inv <- solve(Sigma0)
  prior_prod <- Sigma0_inv %*% mu0
  a0 <- .01
  b0 <- .01
  
  # more convenience
  XtX <- t(X_) %*% X_
  Xty <- t(X_) %*% y
  
  # initialize
  beta <- chol(Sigma0) %*% rnorm(p) + mu0; beta_mcmc[1,] <- beta
  sigma <- invgamma::rinvgamma(1, a0, b0); sigma_mcmc[1,] <- sigma
  sigma2 <- sigma^2
  
  # sampler
  pb <- txtProgressBar(min = 0, max = num_mcmc, style = 3, width = 50, char = "=") 
  for(iter in 2:num_mcmc){
    # beta
    ## assuming Omega is always identity
    V <- solve(1/sigma2 * XtX + Sigma0_inv)
    m <- V %*% (1/sigma2 * Xty + prior_prod)
    
    beta <- chol(V) %*% rnorm(p) + m
    Xb <- X_ %*% beta
    
    # sigma
    a <- a0 + n/2
    b <- c(b0 + .5 * t(y - Xb) %*% (y - Xb))
    sigma <- sqrt(invgamma::rinvgamma(1, a, b))
    sigma2 <- sigma^2
    
    # storage
    beta_mcmc[iter,] <- beta
    sigma_mcmc[iter,] <- sigma
    
    # progress
    setTxtProgressBar(pb, iter)
  }
  close(pb)
  
  samples <- cbind(
    beta = beta_mcmc[(warmup+1):num_mcmc,],
    sigma = sigma_mcmc[(warmup+1):num_mcmc,]
  )
  
  return(samples)
  
}
samples <- ols_gibbs(
  num_mcmc = 5000, 
  y = y, 
  X_ = matrix(1, nrow = n),
  Omega = diag(n),
  seed = 05172022
)
```

```{r, echo = T}
mean(samples[,1])
quantile(samples[,1], c(0.025, 0.975))

mean(samples[,2])
quantile(samples[,2], c(0.025, 0.975))
```

### Simulation with synthetic data

```{r, eval = F}
library(parallel)
sim_ols <- function(nsims, n = 400){
    # convenience function
  nimble_summary <- function(fit, warmup = nrow(fit[[1]])/2, thin = 1){
    # convert to coda for normal summary
    fit_warmup <- lapply(fit, function(x) x[(warmup+1):nrow(x),])
    coda_samples <- as.mcmc.list(lapply(fit_warmup, function(x) as.mcmc(
      x, start = warmup+1, end = nrow(fit), thin = thin
    )))
    
    sum <- summary(coda_samples)
    params <- dimnames(sum$statistics)[[1]]
    tmp_sum <- cbind(sum$statistics, sum$quantiles)
    
    # get r hat / n_eff
    mat <- matrix(NA, nrow = nrow(tmp_sum), ncol = 3)
    colnames(mat) <- c("Rhat", "ess_bulk", "ess_tail")
    for(i in 1:nrow(tmp_sum)){
      tmp <- sapply(fit, function(x) x[,i])
      mat[i,] <- c(Rhat(tmp), ess_bulk(tmp), ess_tail(tmp))
    }
    
    # out 
    out <- cbind(tmp_sum, mat)
    return(out)
  }
  
  sum_tbl <- list()
  pb <- txtProgressBar(min = 0, max = nsims, style = 3, width = 50, char = "=")
  for(sim in 1:nsims){
    # simulate data
    dat <- sim_reg(
      n = n, 
      X = matrix(1, nrow = n),
      beta = 0,
      sigma = 2, 
      Omega = diag(n),
      seed = sim
    )
    
    # fit model - parallel
    tmp_sim <- sim
    this_cluster <- makeCluster(3)
    fit <- parLapply(
      cl = this_cluster,
      X = 1:3,
      fun = ols_gibbs,
      num_mcmc = 5000,
      warmup = 2500,
      y = dat, 
      X_ = matrix(1, nrow = n, ncol = 1),
      Omega = diag(n)
    )
    stopCluster(this_cluster)

    sum <- nimble_summary(fit, warmup = 0)
    sum_tbl[[sim]] <- tibble(
      param = rownames(sum),
      truth = c(0, 2),
      mean = sum[,1],
      lwr = sum[,5],
      upr = sum[,9],
      rhat = sum[,10],
      ess_bulk = sum[,11],
      ess_tail = sum[,12]
    ) %>%
      mutate(sim = tmp_sim)
    
    setTxtProgressBar(pb, sim)
  }
  close(pb)
  
  return(do.call("bind_rows", sum_tbl))
}
ols_sims <- sim_ols(100, 400)
saveRDS(ols_sims, "rds files/ols_sims.rds")
```

```{r}
ols_sims <- readRDS("rds files/ols_sims.rds")
ols_sims %>%
  mutate(
    capture = factor(case_when(
      truth >= lwr & truth <= upr ~ 1, 
      TRUE ~ 0
    ))
  ) %>%
  ggplot() + 
  geom_linerange(
    aes(xmin = lwr, xmax = upr, x = mean, col = capture, y = sim)
  ) +
  facet_wrap(~ param) +
  theme_bw()
```

## Generalized least squares regression

\[
\begin{split}
\boldsymbol{y} &\sim \mathcal{N}(X\boldsymbol{\beta}, \boldsymbol{\Sigma}) \\
\boldsymbol{\Sigma} &= \sigma^2\boldsymbol{\Omega}, \boldsymbol{\Omega}\text{ known}
\end{split}
\]

### Simulated data

```{r}
df <- sim_reg(
  n = 400, 
  X = cbind(
    rep(1, 400),
    rnorm(400)
  ),
  beta = c(0, 1),
  sigma = 2, 
  Omega = exp(-as.matrix(dist(1:400))^2/4),
  seed = 2
)

df %>%
  ggplot() +
  geom_point(aes(x = x1, y = y)) +
  theme_bw()

# ggplot() + 
#   geom_histogram(data = tibble(y = y), aes(x = y)) +
#   theme_bw() +
#   labs(title = "Simulated data, beta = 0, sigma = 2, tau = 1, Omega = exp(-as.matrix(dist(1:n)^2)/25)")

# stan(
#   file = 'stan programs/invgamPars.stan',
#   data = list(l=1.5, u=16),
#   iter = 1,
#   warmup = 0,
#   chains = 1,
#   algorithm = "Fixed_param"
# )
# 4.4, 16
```

### Gibbs sampler

```{r}
# num_mcmc = 5000
# seed = 05172022
# Omega = diag(nrow(y))
# X = matrix(1, nrow = n)
gls_gibbs <- function(seed, num_mcmc, warmup = num_mcmc/2, y, X_, Omega){
  # hoff text pg 189 for reassurance
  
  # seed
  set.seed(seed)
  
  # convenience
  n <- nrow(X_)
  p <- ncol(X_)
  
  # storage
  sigma_mcmc <- matrix(NA, num_mcmc, 1)
  beta_mcmc <- matrix(NA, num_mcmc, p)
  
  # priors
  mu0 <- matrix(0, nrow = p, ncol = 1)
  Sigma0 <- 1000 * diag(1, p, p)
  Sigma0_inv <- solve(Sigma0)
  prior_prod <- Sigma0_inv %*% mu0
  a0 <- .1
  b0 <- .1
  
  # initialize
  beta <- chol(Sigma0) %*% rnorm(p) + mu0; beta_mcmc[1,] <- beta
  # beta <- mvtnorm::rmvnorm(1, mu0, Sigma0); beta_mcmc[1,] <- beta
  sigma <- invgamma::rinvgamma(1, a0, b0); sigma_mcmc[1,] <- sigma
  sigma2 <- sigma^2
  Omega_inv <- solve(Omega + diag(.00001, n, n))
  
  # more convenience
  XtX <- t(X_) %*% X_
  XtOX <- t(X_) %*% Omega_inv %*% X_
  Xty <- t(X_) %*% y
  XtOy <- t(X_) %*% Omega_inv %*% y
  
  # sampler
  pb <- txtProgressBar(min = 0, max = num_mcmc, style = 3, width = 50, char = "=")
  for(iter in 2:num_mcmc){
    # beta
    V <- solve(1/sigma2 * XtOX + Sigma0_inv)
    m <- V %*% (1/sigma2 * XtOy + prior_prod)
    
    beta <- chol(V) %*% rnorm(p) + m
    # beta <- matrix(c(mvtnorm::rmvnorm(1, m, V)), ncol = 1)
    Xb <- X_ %*% beta
    
    # sigma
    a <- a0 + n/2
    # a <- (a0 + n)/2
    b <- c(b0 + .5 * t(y - Xb) %*% Omega_inv %*% (y - Xb))
    # b <- (a0*b0 + t(y - Xb) %*% Omega_inv %*% (y - Xb))/2
    sigma <- sqrt(invgamma::rinvgamma(1, a, b))
    sigma2 <- sigma^2
    
    # storage
    beta_mcmc[iter,] <- beta
    sigma_mcmc[iter,] <- sigma
    
    # progress
    setTxtProgressBar(pb, iter)
  }
  close(pb)
  
  samples <- cbind(
    beta_mcmc[(warmup+1):num_mcmc,],
    sigma_mcmc[(warmup+1):num_mcmc,]
  )
  
  colnames(samples) <- c(paste0(rep("beta[", p), 1:p, rep("]", p)), "sigma")
  
  return(samples)
  
}

samples <- gls_gibbs(
  num_mcmc = 1000, 
  y = df$y, 
  X_ = cbind(
    rep(1, nrow(df)),
    df$x1
  ),
  Omega = exp(-as.matrix(dist(1:nrow(df))^2)/4),
  seed = 102
)
```

```{r, echo = T}
# beta - 0
mean(samples[,1])
quantile(samples[,1], c(0.025, 0.975))

# btea[2] - 1
mean(samples[,2])
quantile(samples[,2], c(0.025, 0.975))

# sigma - 1
mean(samples[,3])
quantile(samples[,3], c(0.025, 0.975))
```

### Simulation with synthetic data

```{r, eval = F}
library(parallel)
sim_gls <- function(nsims, n = 400){
  sum_tbl <- list()
  pb <- txtProgressBar(min = 0, max = nsims, style = 3, width = 50, char = "=")
  for(sim in 1:nsims){
    # simulate data
    df <- sim_reg(
      n = n, 
      X = cbind(
        rep(1, n),
        rnorm(n)
      ),
      beta = c(0, 1),
      sigma = 2, 
      Omega = exp(-as.matrix(dist(1:n))^2/4),
      seed = sim
    )
    
    # fit model - parallel
    tmp_sim <- sim
    this_cluster <- makeCluster(3)
    fit <- parLapply(
      cl = this_cluster,
      X = 1:3,
      fun = gls_gibbs,
      num_mcmc = 5000,
      warmup = 2500,
      y = df$y, 
      X_ = cbind(
        rep(1, nrow(df)),
        df$x1
      ),
      Omega = exp(-as.matrix(dist(1:n)^2)/4)
    )
    stopCluster(this_cluster)

    sum <- nimble_summary(fit, warmup = 0)
    sum_tbl[[sim]] <- tibble(
      param = rownames(sum),
      truth = c(0, 1, 2),
      mean = sum[,1],
      lwr = sum[,5],
      upr = sum[,9],
      rhat = sum[,10],
      ess_bulk = sum[,11],
      ess_tail = sum[,12]
    ) %>%
      mutate(sim = tmp_sim)
    
    setTxtProgressBar(pb, sim)
  }
  close(pb)
  
  return(do.call("bind_rows", sum_tbl))
}
gls_sims <- sim_gls(100, 400)
saveRDS(gls_sims, "rds files/gls_sims.rds")
```

```{r}
gls_sims <- readRDS("rds files/gls_sims.rds")
gls_sims %>%
  mutate(
    capture = factor(case_when(
      truth >= lwr & truth <= upr ~ 1, 
      TRUE ~ 0
    ))
  ) %>%
  ggplot() + 
  geom_linerange(
    aes(xmin = lwr, xmax = upr, x = mean, col = capture, y = sim)
  ) +
  facet_wrap(~ param, scales = "free") +
  theme_bw()
```

# Gaussian processes

```{r}
nimble_summary <- function(fit, warmup = nrow(fit[[1]])/2, thin = 1){
  # convert to coda for normal summary
  fit_warmup <- lapply(fit, function(x) x[(warmup+1):nrow(x),])
  coda_samples <- as.mcmc.list(lapply(fit_warmup, function(x) as.mcmc(
    x, start = warmup+1, end = nrow(fit), thin = thin
  )))
  
  sum <- summary(coda_samples)
  params <- dimnames(sum$statistics)[[1]]
  tmp_sum <- cbind(sum$statistics, sum$quantiles)
  
  # get r hat / n_eff
  mat <- matrix(NA, nrow = nrow(tmp_sum), ncol = 3)
  colnames(mat) <- c("Rhat", "ess_bulk", "ess_tail")
  for(i in 1:nrow(tmp_sum)){
    tmp <- sapply(fit, function(x) x[,i])
    mat[i,] <- c(Rhat(tmp), ess_bulk(tmp), ess_tail(tmp))
  }
  
  # out 
  out <- cbind(tmp_sum, mat)
  return(out)
}
sim_gp <- function(n = 100, seed = 1, sigma = 1, phi = 1, X = matrix(1, nrow = n), beta = 0, delta = 1e-9){
  # function to simulated occupancy on a square grid
  
  # useful functions
  distance <- function(x){
    dist.vec <- parallelDist::parDist(x)
    dist <- as.matrix(dist.vec)
    return(dist)
  }

  # housekeeping
  if((sqrt(n) %% 1) != 0) stop("n should be a perfect square")
  set.seed(seed)
  
  # create grid
  sfc <- st_sfc(st_polygon(list(rbind(c(0,0), c(sqrt(n),0), c(sqrt(n),sqrt(n)), c(0,0)))))
  grid <- st_as_sf(st_make_grid(sfc, cellsize = 1, square = TRUE)) %>% as_tibble
  names(grid) <- "geometry"
  rm(sfc)
  
  # spatial random effects
  coords <- grid %>%
    st_as_sf %>%
    st_centroid %>%
    st_coordinates
  
  dist_mat <- coords %>%
    as.matrix %>%
    distance
  
  # dist_mat <- dist_mat / max(dist_mat) # normalize max dist to 1
  
  Sigma <- sigma^2 * exp(-dist_mat^2 / (2*phi^2)) + diag(delta, dim(dist_mat))
  grid$y <- c(mvtnorm::rmvnorm(1, X %*% beta, Sigma))
  # grid$y <- c(chol(Sigma) %*% rnorm(n) + X %*% beta) 

  out <- list(
    df = grid,
    params = list(
      phi = phi, sigma = sigma, phi = phi, beta = beta
    ),
    dist_mat = dist_mat,
    coords = coords
  )
  
  return(out)
}
```

## Normal response

\[
\begin{split}
\boldsymbol{y} &\sim \mathcal{N}(X\boldsymbol{\beta}, \boldsymbol{\Sigma}) \\
\boldsymbol{\Sigma} &= \sigma^2 \exp\left(-\frac{d_{ij}^2}{2\phi^2}\right)
\end{split}
\]

### Simulated data

```{r}
sim_dat <- sim_gp(n = 10^2, sigma = 1, phi = 2, seed = 06292022, delta = 1e-9)

sim_dat$df %>%
  st_as_sf %>% 
  ggplot() +
  geom_sf(aes(fill = y)) +
  labs(
    title = "Simulated response (y)",
    subtitle = bquote(beta == 0 ~ "," ~ sigma == 1 ~ "," ~ phi == 2)
  ) +
  theme_bw()


# stan(
#   file = 'stan programs/invgamPars.stan',
#   data = list(l=1.1, u=13),
#   iter = 1,
#   warmup = 0,
#   chains = 1,
#   algorithm = "Fixed_param"
# ) # 4, 11.2
# curve(dinvgamma(x, .01, .01), from = 0, to = 11.2)
# pinvgamma(2, 5, 11.2)
```

### Metropolis within Gibbs sampler

```{r}
# num_mcmc = 5000
# seed = 05172022
# X_ = matrix(1, nrow = length(sim_dat$df$y))
# y <- sim_dat$df$y
# warmup = num_mcmc/2
# phi_a = 4
# phi_b = 11.2
# sigma_a = .1
# sigma_b = .1
# dist <- sim_dat$dist_mat
# delta = 1e-9
# prop_sd = .1

gp_mhgibbs <- function(
    seed, num_mcmc, warmup = num_mcmc/2, y, X_, dist, 
    phi_a = .1, phi_b = .1, sigma_a = .1, sigma_b = .1,
    delta = .0001, 
    initial_prop_var = .01, adapt = TRUE, adapt_period = .1*num_mcmc, sd = 2.4^2, epsilon = 1e-9){
  # hoff text pg 189 for reassurance on posteriors
  # heikki haario (2001) - An adaptive Metropolis algorithm
  
  # seed
  set.seed(seed)
  
  # convenience
  n <- nrow(X_)
  p <- ncol(X_)
  
  # storage
  sigma_mcmc <- matrix(NA, num_mcmc, 1)
  phi_mcmc <- matrix(NA, num_mcmc, 1)
  accept_ratio <- matrix(0, num_mcmc, 1)
  beta_mcmc <- matrix(NA, num_mcmc, p)
  
  # priors
  mu0 <- matrix(0, nrow = p, ncol = 1)
  Sigma0 <- 100 * diag(1, p, p)
  Sigma0_inv <- solve(Sigma0)
  prior_prod <- Sigma0_inv %*% mu0
  a0 <- sigma_a
  b0 <- sigma_b
  
  # initialize
  beta <- chol(Sigma0) %*% rnorm(p) + mu0; beta_mcmc[1,] <- beta
  sigma <- invgamma::rinvgamma(1, a0, b0); sigma_mcmc[1,] <- sigma
  sigma2 <- sigma^2
  phi <- invgamma::rinvgamma(1, phi_a, phi_b); phi_mcmc[1,] <- phi
  phi2 <- phi^2
  Omega <- exp(-dist^2/(2*phi2)) + diag(delta, n, n)
  Omega_inv <- solve(Omega)

  XtOX <- t(X_) %*% Omega_inv %*% X_
  XtOy <- t(X_) %*% Omega_inv %*% y
  
  # adaptive
  Ct <- initial_prop_var
  
  # sampler
  message(paste0("Beginning sampling at "), Sys.time())
  pb <- txtProgressBar(min = 0, max = num_mcmc, style = 3, width = 50, char = "=")
  for(iter in 2:num_mcmc){
    # beta
    V <- solve(1/sigma2 * XtOX + Sigma0_inv) + diag(delta, p, p)
    m <- V %*% (1/sigma2 * XtOy + prior_prod)
    
    beta <- chol(V) %*% rnorm(p) + m
    Xb <- X_ %*% beta
    
    # sigma
    a <- a0 + n/2
    b <- c(b0 + .5 * t(y - Xb) %*% Omega_inv %*% (y - Xb))
    sigma <- sqrt(invgamma::rinvgamma(1, a, b))
    sigma2 <- sigma^2
    
    # phi - metropolis
    ## adaptive
    if(adapt){
      if(iter <= adapt_period){
        Ct <- initial_prop_var
      } else if(iter > adapt_period){
        Ct <- sd * cov(phi_mcmc[1:(iter-1),,drop = F]) + sd * epsilon
      }
    }
    
    ## proposal
    phi_s <- -1
    while(phi_s <= 0) phi_s <- phi + rnorm(1, 0, sqrt(Ct))
    phi2_s <- phi_s^2
    Omega_s <- exp(-dist^2/(2*phi2_s)) + diag(delta, n, n)

    ## evaluate proposal
    log_post_current <- mvtnorm::dmvnorm(y, Xb, sigma2 * Omega, log = T) + invgamma::dinvgamma(phi, phi_a, phi_b, log = T)
    log_post_s <- mvtnorm::dmvnorm(y, Xb, sigma2 * Omega_s, log = T) + invgamma::dinvgamma(phi_s, phi_a, phi_b, log = T)
    log_r <- log_post_s - log_post_current
    if(log(runif(1)) < log_r){
      phi <- phi_s
      phi2 <- phi_s^2
      Omega <- exp(-dist^2/(2*phi2)) + diag(delta, n, n)
      Omega_inv <- solve(Omega)
      XtOX <- t(X_) %*% Omega_inv %*% X_
      XtOy <- t(X_) %*% Omega_inv %*% y

      accept_ratio[iter,] <- 1
    }
    
    # storage
    beta_mcmc[iter,] <- beta
    sigma_mcmc[iter,] <- sigma
    phi_mcmc[iter,] <- phi
    
    # progress
    setTxtProgressBar(pb, iter)
  }
  close(pb)
  message(paste0("Ending sampling at "), Sys.time())
  
  samples <- cbind(
    beta_mcmc[(warmup+1):num_mcmc,],
    sigma_mcmc[(warmup+1):num_mcmc,],
    phi_mcmc[(warmup+1):num_mcmc,]
  )
  
  colnames(samples) <- c(paste0(rep("beta[", p), 1:p, rep("]", p)), "sigma", "phi")
  
  return(
    list(
      samples = samples,
      accept_ratio = accept_ratio
    )
  )
  
}

# curve(dinvgamma(x, .01, sd(sim_dat$df$y)), 0, 10)

# parallel
this_cluster <- makeCluster(3)
samples <- parLapply(
  cl = this_cluster,
  X = 1:3,
  fun = gp_mhgibbs,
  num_mcmc = 100000,
  warmup = 50000,
  y = sim_dat$df$y, 
  X_ = cbind(
    rep(1, nrow(sim_dat$df))
  ),
  dist = sim_dat$dist_mat,
  phi_a = 4,
  phi_b = 11.2,
  sigma_a = 1,
  sigma_b = 1,
  initial_prop_var = .05^2,
  adapt = FALSE,
  delta = 1e-09
)
stopCluster(this_cluster)

# saveRDS(samples, "rds files/gibbs_gp.rds")
```

```{r, echo = T}
samples <- readRDS("rds files/gibbs_gp.rds")
colMeans(samples[[1]]$accept_ratio)
nimble_summary(list(samples[[1]]$samples, samples[[2]]$samples, samples[[3]]$samples), warmup = 0)

# # beta - 0
# mean(samples[[1]][,1])
# quantile(samples[[1]][,1], c(0.025, 0.975))
# plot(samples[[1]][,1], type = "l")
# 
# # sigma - 1
# mean(samples[[1]][,2])
# quantile(samples[[1]][,2], c(0.025, 0.975))
# plot(samples[[1]][,2], type = "l")
# 
# # phi - 2
# mean(samples[[1]][,3])
# quantile(samples[[1]][,3], c(0.025, 0.975))
plot(samples[[1]][[1]][,2], type = "l")
lines(samples[[2]][[1]][,2], type = "l", col = 2)
lines(samples[[3]][[1]][,2], type = "l", col = 3)

plot(samples[[1]][[1]][,3], type = "l")
lines(samples[[2]][[1]][,3], type = "l", col = 2)
lines(samples[[3]][[1]][,3], type = "l", col = 3)
```

### Stan

```{r}
fit <- stan(
  file = "stan programs/gp.stan",
  data = list(
    N = length(sim_dat$df$y),
    p = 1,
    X = matrix(1, nrow = 100, ncol = 1),
    y = c(sim_dat$df$y),
    coords = sim_dat$coords
  ),
  iter = 5000,
  warmup = 2500,
  chains = 3, 
  include = TRUE,
  pars = c("sigma", "beta", "phi")
)
saveRDS(fit, "stan fits/gp.rds")
```

```{r}
fit2 <- readRDS("stan fits/gp.rds")
summary(fit2)$summary
```

### Simulated data

```{r}
sim_dat <- sim_gp(n = 10^2, sigma = 1, phi = 3, seed = 06302022, delta = 1e-9)

# (2, 3): gibbs good - 06292022, 06302022

sim_dat$df %>%
  st_as_sf %>% 
  ggplot() +
  geom_sf(aes(fill = y)) +
  labs(
    title = "Simulated response (y)",
    subtitle = bquote(beta == 0 ~ "," ~ sigma == 1 ~ "," ~ phi == 2)
  ) +
  theme_bw()


# stan(
#   file = 'stan programs/invgamPars.stan',
#   data = list(l=1.1, u=13),
#   iter = 1,
#   warmup = 0,
#   chains = 1,
#   algorithm = "Fixed_param"
# ) # 4, 11.2
# curve(dinvgamma(x, .01, .01), from = 0, to = 11.2)
# pinvgamma(2, 5, 11.2)
```

### Metropolis within Gibbs sampler

```{r}
# parallel
this_cluster <- makeCluster(3)
samples <- parLapply(
  cl = this_cluster,
  X = 1:3,
  fun = gp_mhgibbs,
  num_mcmc = 15000,
  warmup = 10000,
  y = sim_dat$df$y, 
  X_ = cbind(
    rep(1, nrow(sim_dat$df))
  ),
  dist = sim_dat$dist_mat,
  phi_a = 1,
  phi_b = 1,
  sigma_a = 1,
  sigma_b = 1,
  initial_prop_var = .05^2,
  adapt = FALSE,
  delta = 1e-09
)
stopCluster(this_cluster)

# saveRDS(samples, "rds files/gibbs_gp2.rds")
```

```{r, echo = T}
samples <- readRDS("rds files/gibbs_gp2.rds")
colMeans(samples[[1]]$accept_ratio)
nimble_summary(list(samples[[1]]$samples, samples[[2]]$samples, samples[[3]]$samples), warmup = 0)

# # beta - 0
# mean(samples[[1]][,1])
# quantile(samples[[1]][,1], c(0.025, 0.975))
# plot(samples[[1]][,1], type = "l")
# 
# # sigma - 1
# mean(samples[[1]][,2])
# quantile(samples[[1]][,2], c(0.025, 0.975))
# plot(samples[[1]][,2], type = "l")
# 
# # phi - 2
# mean(samples[[1]][,3])
# quantile(samples[[1]][,3], c(0.025, 0.975))
plot(samples[[1]][[1]][,2], type = "l")
lines(samples[[2]][[1]][,2], type = "l", col = 2)
lines(samples[[3]][[1]][,2], type = "l", col = 3)

plot(samples[[1]][[1]][,3], type = "l")
lines(samples[[2]][[1]][,3], type = "l", col = 2)
lines(samples[[3]][[1]][,3], type = "l", col = 3)
```

### Stan

```{r, eval = F}
fit <- stan(
  file = "stan programs/gp.stan",
  data = list(
    N = length(sim_dat$df$y),
    p = 1,
    X = matrix(1, nrow = 100, ncol = 1),
    y = c(sim_dat$df$y),
    coords = sim_dat$coords
  ),
  iter = 5000,
  warmup = 2500,
  chains = 3, 
  include = TRUE,
  pars = c("sigma", "beta", "phi")
)
saveRDS(fit, "stan fits/gp2.rds")
```

```{r, eval = F}
fit2 <- readRDS("stan fits/gp2.rds")
summary(fit2)$summary
```

### Simulation with synthetic data - (1, 3)

```{r, eval = F}
library(parallel)
gp_sim <- function(nsims, n = 100){
  sum_tbl <- list()
  pb <- txtProgressBar(min = 0, max = nsims, style = 3, width = 50, char = "=")
  for(sim in 1:nsims){
    # simulate data
    sim_dat <- sim_gp(
      n = n, 
      sigma = 1, 
      phi = 3, 
      seed = sim,
      delta = 1e-9
    )
    
    # fit model - parallel
    tmp_sim <- sim
    this_cluster <- makeCluster(3)
    fit <- parLapply(
      cl = this_cluster,
      X = 1:3,
      fun = gp_mhgibbs,
      num_mcmc = 15000,
      warmup = 10000,
      y = sim_dat$df$y, 
      X_ = cbind(
        rep(1, nrow(sim_dat$df))
      ),
      dist = sim_dat$dist_mat,
      phi_a = 1,
      phi_b = 1,
      sigma_a = 1,
      sigma_b = 1,
      initial_prop_var = .05^2,
      adapt = FALSE,
      delta = 1e-09
    )
    stopCluster(this_cluster)
    
    sum <- nimble_summary(list(fit[[1]]$samples, fit[[2]]$samples, fit[[3]]$samples), warmup = 0)
    sum_tbl[[sim]] <- tibble(
      param = rownames(sum),
      truth = c(0, 1, 3),
      mean = sum[,1],
      lwr = sum[,5],
      upr = sum[,9],
      rhat = sum[,10],
      ess_bulk = sum[,11],
      ess_tail = sum[,12]
    ) %>%
      mutate(sim = tmp_sim)
    
    setTxtProgressBar(pb, sim)
  }
  close(pb)
  
  return(do.call("bind_rows", sum_tbl))
}
gp_sims <- gp_sim(100, 100)
saveRDS(gp_sims, "rds files/gp_sims_1_3.rds")
```

```{r}
gp_sims <- readRDS("rds files/gp_sims_1_3.rds")
gp_sims %>%
  mutate(
    capture = factor(case_when(
      truth >= lwr & truth <= upr ~ 1, 
      TRUE ~ 0
    ))
  ) %>%
  ggplot() + 
  geom_linerange(
    aes(xmin = lwr, xmax = upr, x = mean, col = capture, y = sim)
  ) +
  facet_wrap(~ param, scales = "free_x") +
  theme_bw()
```

## Prediction - no latent process, just predict at unobserved locations

### One dataset

```{r}
# n = 100
# seed = 1
# sigma = 1
# phi = 1
# X = matrix(1, nrow = n)
# beta = 0
# delta = 1e-9
# pred_pro = .4

sim_gp_predict <- function(n = 100, seed = 1, sigma = 1, phi = 1, X = matrix(1, nrow = n), beta = 0, delta = 1e-9, pred_prop = .4){
  # function to simulated occupancy on a square grid
  
  # useful functions
  distance <- function(x){
    dist.vec <- parallelDist::parDist(x)
    dist <- as.matrix(dist.vec)
    return(dist)
  }

  # housekeeping
  if((sqrt(n) %% 1) != 0) stop("n should be a perfect square")
  set.seed(seed)
  
  # create grid
  sfc <- st_sfc(st_polygon(list(rbind(c(0,0), c(sqrt(n),0), c(sqrt(n),sqrt(n)), c(0,0)))))
  grid <- st_as_sf(st_make_grid(sfc, cellsize = 1, square = TRUE)) %>% as_tibble
  names(grid) <- "geometry"
  rm(sfc)
  
  # spatial random effects
  coords <- grid %>%
    st_as_sf %>%
    st_centroid %>%
    st_coordinates
  
  dist_mat <- coords %>%
    as.matrix %>%
    distance
  
  Sigma <- sigma^2 * exp(-dist_mat^2 / (2*phi^2)) + diag(delta, dim(dist_mat))
  grid$y <- c(mvtnorm::rmvnorm(1, X %*% beta, Sigma))
  grid$obs_ind <- factor(rbinom(n, size = 1, prob = 1 - pred_prop))
  # grid$y <- c(chol(Sigma) %*% rnorm(n) + X %*% beta) 
  
  grid <- grid %>%
    arrange(desc(obs_ind))
    
  # reorder spatial random effects
  dist_mat <- grid %>%
    st_as_sf %>%
    st_centroid %>%
    st_coordinates %>%
    as.matrix %>%
    distance
  
  out <- list(
    df = grid,
    params = list(
      phi = phi, sigma = sigma, phi = phi, beta = beta
    ),
    dist_mat = dist_mat,
    coords = coords
  )
  
  return(out)
}
data <- sim_gp_predict(n = 10^2, sigma = 1, phi = 3, seed = 06302022, delta = 1e-9)


p1 <- data$df %>%
  st_as_sf %>%
  ggplot() +
  geom_sf(aes(fill = y)) +
  theme_bw() +
  labs(title = "Population")

p2 <- data$df %>%
  st_as_sf %>%
  filter(obs_ind == 1) %>%
  ggplot() +
  geom_sf(aes(fill = y)) +
  theme_bw() +
  labs(title = "Observed data")

gridExtra::grid.arrange(p1, p2, nrow = 1)
```

```{r}
# num_mcmc = 10000
# warmup = 5000
# y = data$df %>% filter(obs_ind == 1) %>% select(y) %>% unlist %>% unname
# X_ = cbind(
#   rep(1, sum(data$df$obs_ind == 1))
# )
# dist = data$dist_mat
# phi_a = 4
# phi_b = 11.2
# sigma_a = 1
# sigma_b = 1
# initial_prop_var = .05^2
# adapt = FALSE
# delta = 1e-09

gp_mhgibbs_predict <- function(
    seed, num_mcmc, warmup = num_mcmc/2, y, X_, dist, 
    phi_a = .1, phi_b = .1, sigma_a = .1, sigma_b = .1,
    delta = .0001, 
    initial_prop_var = .01, adapt = TRUE, adapt_period = .1*num_mcmc, sd = 2.4^2, epsilon = 1e-9){
  # hoff text pg 189 for reassurance on posteriors
  # heikki haario (2001) - An adaptive Metropolis algorithm
  
  # seed
  set.seed(seed)
  
  # convenience
  N <- dim(dist)[1]
  n <- nrow(X_)
  p <- ncol(X_)
  
  # sort distances
  dist11 <- dist[1:n, 1:n]
  dist12 <- dist[1:n, (n+1):N]
  dist22 <- dist[(n+1):N, (n+1):N]
  
  # storage
  sigma_mcmc <- matrix(NA, num_mcmc, 1)
  phi_mcmc <- matrix(NA, num_mcmc, 1)
  accept_ratio <- matrix(0, num_mcmc, 1)
  beta_mcmc <- matrix(NA, num_mcmc, p)
  z_mcmc <- matrix(NA, num_mcmc, N - n)
  
  # priors
  mu0 <- matrix(0, nrow = p, ncol = 1)
  Sigma0 <- 10 * diag(1, p, p)
  Sigma0_inv <- solve(Sigma0)
  prior_prod <- Sigma0_inv %*% mu0
  a0 <- sigma_a
  b0 <- sigma_b
  
  # initialize
  beta <- chol(Sigma0) %*% rnorm(p) + mu0; beta_mcmc[1,] <- beta
  sigma <- invgamma::rinvgamma(1, a0, b0); sigma_mcmc[1,] <- sigma
  sigma2 <- sigma^2
  phi <- invgamma::rinvgamma(1, phi_a, phi_b); phi_mcmc[1,] <- phi
  phi2 <- phi^2
  Omega <- exp(-dist11^2/(2*phi2)) + diag(delta, n, n)
  Omega_inv <- solve(Omega)

  XtOX <- t(X_) %*% Omega_inv %*% X_
  XtOy <- t(X_) %*% Omega_inv %*% y
  
  # adaptive
  Ct <- initial_prop_var
  
  # sampler
  message(paste0("Beginning sampling at "), Sys.time())
  pb <- txtProgressBar(min = 0, max = num_mcmc, style = 3, width = 50, char = "=")
  for(iter in 2:num_mcmc){
    # beta
    V <- solve(1/sigma2 * XtOX + Sigma0_inv) + diag(delta, p, p)
    m <- V %*% (1/sigma2 * XtOy + prior_prod)
    
    beta <- chol(V) %*% rnorm(p) + m
    Xb <- X_ %*% beta
    
    # sigma
    a <- a0 + n/2
    b <- c(b0 + .5 * t(y - Xb) %*% Omega_inv %*% (y - Xb))
    sigma <- sqrt(invgamma::rinvgamma(1, a, b))
    sigma2 <- sigma^2
    
    # phi - metropolis
    ## adaptive
    if(adapt){
      if(iter <= adapt_period){
        Ct <- initial_prop_var
      } else if(iter > adapt_period){
        Ct <- sd * cov(phi_mcmc[1:(iter-1),,drop = F]) + sd * epsilon
      }
    }
    
    ## proposal
    phi_s <- -1
    while(phi_s <= 0) phi_s <- phi + rnorm(1, 0, sqrt(Ct))
    phi2_s <- phi_s^2
    Omega_s <- exp(-dist11^2/(2*phi2_s)) + diag(delta, n, n)

    ## evaluate proposal
    log_post_current <- mvtnorm::dmvnorm(y, Xb, sigma2 * Omega, log = T) + invgamma::dinvgamma(phi, phi_a, phi_b, log = T)
    log_post_s <- mvtnorm::dmvnorm(y, Xb, sigma2 * Omega_s, log = T) + invgamma::dinvgamma(phi_s, phi_a, phi_b, log = T)
    log_r <- log_post_s - log_post_current
    if(log(runif(1)) < log_r){
      phi <- phi_s
      phi2 <- phi_s^2
      Omega <- exp(-dist11^2/(2*phi2)) + diag(delta, n, n)
      Omega_inv <- solve(Omega)
      XtOX <- t(X_) %*% Omega_inv %*% X_
      XtOy <- t(X_) %*% Omega_inv %*% y

      accept_ratio[iter,] <- 1
    }
    
    # predict
    if(iter > warmup){
      Sigma11_inv <- (1/sigma^2) * Omega_inv
      Sigma12 <- sigma^2 * exp(-dist12^2 / (2*phi2))
      Sigma22 <- sigma^2 * exp(-dist22^2 / (2*phi2))

      t.Sigma11_inv.Sigma12 <- t(Sigma11_inv %*% Sigma12)
      Sigma2.1 <- Sigma22 - t.Sigma11_inv.Sigma12 %*% Sigma12
      Sigma2.1[lower.tri(Sigma2.1)] = t(Sigma2.1)[lower.tri(Sigma2.1)]
      mu2.1 <- t.Sigma11_inv.Sigma12 %*% (matrix(c(y), ncol = 1) - Xb)

      z <- mvtnorm::rmvnorm(1, mu2.1, Sigma2.1)
      z_mcmc[iter,] <- z
    }

    # z <- chol(Sigma2.1 + diag(delta, dim(Sigma2.1))) %*% rnorm(N-n) + mu2.1
    
    # storage
    beta_mcmc[iter,] <- beta
    sigma_mcmc[iter,] <- sigma
    phi_mcmc[iter,] <- phi

    # progress
    setTxtProgressBar(pb, iter)
  }
  close(pb)
  message(paste0("Ending sampling at "), Sys.time())
  
  samples <- cbind(
    beta_mcmc[(warmup+1):num_mcmc,],
    sigma_mcmc[(warmup+1):num_mcmc,],
    phi_mcmc[(warmup+1):num_mcmc,],
    z_mcmc[(warmup+1):num_mcmc,]
  )
  
  colnames(samples) <- c(
    paste0(rep("beta[", p), 1:p, rep("]", p)), 
    "sigma", 
    "phi",
    paste0(rep("z[", N-n), 1:(N-n), rep("]", N-n))
  )
  
  return(
    list(
      samples = samples,
      accept_ratio = accept_ratio
    )
  )
  
}

# parallel
this_cluster <- makeCluster(3)
samples <- parLapply(
  cl = this_cluster,
  X = 1:3,
  fun = gp_mhgibbs_predict,
  num_mcmc = 10000,
  warmup = 5000,
  y = data$df %>% filter(obs_ind == 1) %>% select(y) %>% unlist %>% unname, 
  X_ = cbind(
    rep(1, sum(data$df$obs_ind == 1))
  ),
  dist = data$dist_mat,
  phi_a = 4,
  phi_b = 11.2,
  sigma_a = 1,
  sigma_b = 1,
  initial_prop_var = .075^2,
  adapt = TRUE,
  delta = 1e-06
)
stopCluster(this_cluster)

# saveRDS(samples, "rds files/gibbs_gp_predict.rds")
```

```{r}
samples <- readRDS("rds files/gibbs_gp_predict.rds")
colMeans(samples[[1]]$accept_ratio)
nimble_summary(list(samples[[1]]$samples, samples[[2]]$samples, samples[[3]]$samples), warmup = 0)

plot(samples[[1]][[1]][,2], type = "l")
lines(samples[[2]][[1]][,2], type = "l", col = 2)
lines(samples[[3]][[1]][,2], type = "l", col = 3)

plot(samples[[1]][[1]][,3], type = "l")
lines(samples[[2]][[1]][,3], type = "l", col = 2)
lines(samples[[3]][[1]][,3], type = "l", col = 3)
```


```{r}
p1 <- data$df %>%
  st_as_sf %>%
  ggplot() +
  geom_sf(aes(fill = y)) +
  theme_bw() +
  labs(title = "Population")

p2 <- data$df %>%
  st_as_sf %>%
  filter(obs_ind == 1) %>%
  ggplot() +
  geom_sf(aes(fill = y)) +
  theme_bw() +
  labs(title = "Observed data")

gridExtra::grid.arrange(p1, p2, nrow = 1)
```

### Simulation with synthetic data

```{r, eval = F}
library(parallel)
gp_sim_predict <- function(nsims, n = 100){
  sum_tbl <- list()
  pb <- txtProgressBar(min = 0, max = nsims, style = 3, width = 50, char = "=")
  for(sim in 1:nsims){
    # simulate data
    sim_dat <- sim_gp_predict(
      n = n, 
      sigma = 1, 
      phi = 3, 
      seed = sim,
      delta = 1e-9
    )
    
    # fit model - parallel
    tmp_sim <- sim
    this_cluster <- makeCluster(3)
    samples <- parLapply(
      cl = this_cluster,
      X = 1:3,
      fun = gp_mhgibbs_predict,
      num_mcmc = 15000,
      warmup = 10000,
      y = sim_dat$df %>% filter(obs_ind == 1) %>% select(y) %>% unlist %>% unname, 
      X_ = cbind(
        rep(1, sum(sim_dat$df$obs_ind == 1))
      ),
      dist = sim_dat$dist_mat,
      phi_a = 4,
      phi_b = 11.2,
      sigma_a = 1,
      sigma_b = 1,
      initial_prop_var = .075^2,
      adapt = TRUE,
      delta = 1e-06
    )
    stopCluster(this_cluster)
    
    sum <- nimble_summary(list(samples[[1]]$samples, samples[[2]]$samples, samples[[3]]$samples), warmup = 0)
    sum_tbl[[sim]] <- tibble(
      param = rownames(sum),
      truth = c(0, 1, 3, sim_dat$df %>% filter(obs_ind == 0) %>% select(y) %>% unlist %>% unname),
      mean = sum[,1],
      lwr = sum[,5],
      upr = sum[,9],
      rhat = sum[,10],
      ess_bulk = sum[,11],
      ess_tail = sum[,12]
    ) %>%
      mutate(sim = tmp_sim)
    
    setTxtProgressBar(pb, sim)
  }
  close(pb)
  
  return(do.call("bind_rows", sum_tbl))
}
gp_sims_predict <- gp_sim_predict(100, 100)
saveRDS(gp_sims_predict, "rds files/gp_sims_predict_1_3.rds")
```

```{r}
gp_sims <- readRDS("rds files/gp_sims_predict_1_3.rds")
gp_sims %>%
  filter(!grepl("z[[]", param)) %>%
  mutate(
    capture = factor(case_when(
      truth >= lwr & truth <= upr ~ 1, 
      TRUE ~ 0
    ))
  ) %>%
  ggplot() + 
  geom_linerange(
    aes(xmin = lwr, xmax = upr, x = mean, col = capture, y = sim)
  ) +
  facet_wrap(~ param, scales = "free_x") +
  theme_bw()

gp_sims %>%
  filter(grepl("z[[]", param)) %>%
  mutate(
    capture = factor(case_when(
      truth >= lwr & truth <= upr ~ 1, 
      TRUE ~ 0
    ))
  ) %>%
  ggplot() + 
  geom_linerange(
    aes(xmin = lwr, xmax = upr, x = mean, col = capture, y = sim)
  ) +
  facet_wrap(~ param, scales = "free_x") +
  theme_bw()
```

## Prediction - latent process

__Spatial process__
\[
\begin{split}
\boldsymbol{z} &\sim \mathcal{N}(\mu, \boldsymbol{\Sigma}), \hspace{5mm}
\boldsymbol{\Sigma} &= \sigma^2 \exp\left(-\frac{d_{ij}^2}{2\phi^2}\right)
\end{split}
\]

__Observation process__
\[
\begin{split}
y_i &\sim N(x'_i \boldsymbol{\beta} + z^*_i\alpha, 1) \\
\boldsymbol{z}^* &\sim \mathcal{N}(\mu_{2|1}, \Sigma_{2_1})
\end{split}
\]
where $\Sigma_{2|1} = \Sigma_{22} - (\Sigma_{11}^{-1}\Sigma_{12})' \Sigma_{12}$ and $\mu_{2|1} = (\Sigma_{11}^{-1}\Sigma_{12})' (y - \mu_{11})$

```{r}
# n = 100
# seed = 1
# sigma = 1
# phi = 1
# mu = 0
# X = matrix(1, nrow = n)
# beta = 0
# alpha = 1
# delta = 1e-9
# obs_y_prop = .6
# obs_z_prop = .7
# colocate = "none"

sim_latentgp_predict <- function(n = 100, seed = 1, sigma = 1, phi = 1, mu = 0, X = matrix(1, nrow = n), beta = 0, alpha = 1, delta = 1e-9, obs_y_prop = .6, obs_z_prop = .5, colocate = "none"){
  # useful functions
  distance <- function(x){
    dist.vec <- parallelDist::parDist(x)
    dist <- as.matrix(dist.vec)
    return(dist)
  }

  # housekeeping
  if((sqrt(n) %% 1) != 0) stop("n should be a perfect square")
  set.seed(seed)
  
  # create grid
  sfc <- st_sfc(st_polygon(list(rbind(c(0,0), c(sqrt(n),0), c(sqrt(n),sqrt(n)), c(0,0)))))
  grid <- st_as_sf(st_make_grid(sfc, cellsize = 1, square = TRUE)) %>% as_tibble
  names(grid) <- "geometry"
  rm(sfc)
  
  # spatial random effects
  coords <- grid %>%
    st_as_sf %>%
    st_centroid %>%
    st_coordinates

  dist_mat <- coords %>%
    as.matrix %>%
    distance
  
  Sigma <- sigma^2 * exp(-dist_mat^2 / (2*phi^2)) + diag(delta, dim(dist_mat))
  grid$z <- c(mvtnorm::rmvnorm(1, rep(mu, n), Sigma))
  grid$y <- c(rnorm(n, X %*% beta + grid$z * alpha, 1))
  
  # various degrees of masking depending on colocation
  if(colocate == "none"){
    grid2 <- grid %>%
      mutate(obs_y_ind = rbinom(n, 1, obs_y_prop))
    
    if((obs_z_prop * n) >= (n - (obs_y_prop * n))){
      grid2$obs_z_ind <- ifelse(grid2$obs_y_ind == 1, 0, 1)
    } else{
      grid2$obs_z_ind  <- rep(0, n)
      grid2$obs_z_ind[which(grid2$obs_y_ind == 0)] <- rbinom(sum(grid2$obs_y_ind == 0), 1, obs_z_prop)
    }
  } else if(colocate == "all"){
    grid2 <- grid %>%
      mutate(obs_y_ind = rbinom(n, 1, obs_y_prop))
    
    if((obs_z_prop * n) >= (obs_y_prop * n)){
      grid2$obs_z_ind <- ifelse(grid2$obs_y_ind == 1, 1, 0)
      grid2$obs_z_ind[which(grid2$obs_y_ind == 0)] <- rbinom(sum(grid2$obs_y_ind == 0), 1, (obs_z_prop - obs_y_prop))
    } else{
      grid2$obs_z_ind <- rep(0, n)
      grid2$obs_z_ind[which(grid2$obs_y_ind == 1)] <-  rbinom(sum(grid2$obs_y_ind == 1), 1, obs_z_prop)
    }
    
  } else{
    grid2 <- grid %>%
      mutate(obs_y_ind = rbinom(n, 1, obs_y_prop)) %>%
      mutate(obs_z_ind = rbinom(n, 1, obs_z_prop))
  }
  
  grid2 <- grid2 %>%
    mutate(
      obs_y = ifelse(obs_y_ind == 1, y, NA),
      obs_z = ifelse(obs_z_ind == 1, z, NA)
    )

  out <- list(
    df = grid2,
    params = list(
      phi = phi, sigma = sigma, phi = phi, beta = beta, alpha = alpha
    ),
    dist_mat = dist_mat,
    coords = coords
  )
  
  return(out)
}
data <- sim_latentgp_predict(n = 10^2, sigma = 1, phi = 3, seed = 06302022, delta = 1e-9, colocate = "none")

p1 <- data$df %>%
  st_as_sf %>%
  ggplot() +
  geom_sf(aes(fill = z)) +
  theme_bw() +
  labs(title = "Population spatial effects")

p2 <- data$df %>%
  st_as_sf %>%
  filter(obs_z_ind == 1) %>%
  ggplot() +
  geom_sf(aes(fill = z)) +
  theme_bw() +
  labs(title = "Observed spatial effects")

p3 <- data$df %>%
  st_as_sf %>%
  ggplot() +
  geom_sf(aes(fill = y)) +
  theme_bw() +
  labs(title = "Population response")

p4 <- data$df %>%
  st_as_sf %>%
  filter(obs_y_ind == 1) %>%
  ggplot() +
  geom_sf(aes(fill = y)) +
  theme_bw() +
  labs(title = "Observed response")

gridExtra::grid.arrange(p1, p2, p3, p4, nrow = 2, ncol = 2)
```

### Gibbs sampler

```{r}
# dat = data$df
# resp_ind = "obs_y_ind"
# resp = "obs_y"
# sp_ind = "obs_z_ind"
# sp = "obs_z"

data_prep <- function(dat, resp_ind = "obs_y_ind", resp = "obs_y", sp_ind = "obs_z_ind", sp = "obs_z"){
  # useful functions
  distance <- function(x){
    dist.vec <- parallelDist::parDist(x)
    dist <- as.matrix(dist.vec)
    return(dist)
  }
  
  # storage
  out <- list()
  out$data <- dat
  dat$ndx <- 1:nrow(dat)
  
  # grab response data and spatial data
  out$resp <- unlist(unname(dat[which(dat[,resp_ind] == 1),resp]))
  out$resp_row_num <- unlist(unname(dat[which(dat[,resp_ind] == 1),"ndx"]))
  out$sp <- unlist(unname(dat[which(dat[,sp_ind] == 1),sp]))
  out$sp_row_num <- unlist(unname(dat[which(dat[,sp_ind] == 1),"ndx"]))
  
  out$z_atobsy <- unlist(unname(dat[which(dat[,resp_ind] == 1), sp]))
  
  # observed distance matrix
  out$dist11 <- dat[which(dat[,sp_ind] == 1),] %>%
    st_as_sf %>%
    st_centroid %>%
    st_coordinates %>%
    as.matrix %>%
    distance
  
  # prediction distance matrix
  out$dist22 <- dat[which(dat[,sp_ind] == 0 & dat[,resp_ind] == 1),] %>%
    st_as_sf %>%
    st_centroid %>%
    st_coordinates %>%
    as.matrix %>%
    distance
  
  dist12 <- bind_rows(
    dat[which(dat[,sp_ind] == 1),],
    dat[which(dat[,sp_ind] == 0 & dat[,resp_ind] == 1),]
  ) %>%
    st_as_sf %>%
    st_centroid %>%
    st_coordinates %>%
    as.matrix %>%
    distance
    
  out$dist12 <- dist12[
    1:(dim(out$dist11)[1]),
    (dim(out$dist11)[1] + 1):(dim(dist12)[1])
  ]
  
  return(out)
  
}

data_list <- data_prep(
  data$df
)

# num_mcmc = 10000
# warmup = 5000
# X_ = cbind(
#   rep(1, length(data_list$resp))
# )
# phi_a = 4
# phi_b = 11.2
# sigma_a = 1
# sigma_b = 1
# initial_prop_var = .05^2
# adapt = FALSE
# delta = 1e-6
# seed = 1

latentgp_mhgibbs_predict <- function(
    seed, num_mcmc, warmup = num_mcmc/2, 
    data_list, X_,
    phi_a = .1, phi_b = .1, sigma_a = .1, sigma_b = .1, delta = .0001, 
    initial_prop_var = .01, adapt = TRUE, adapt_period = .1*num_mcmc, sd = 2.4^2, epsilon = 1e-6){
  # hoff text pg 189 for reassurance on posteriors
  # heikki haario (2001) - An adaptive Metropolis algorithm
  
  # seed
  set.seed(seed)
  
  # convenience
  n <- dim(data_list$dist11)[1]
  m <- dim(data_list$dist22)[1]
  p <- ncol(X_)
  dist11 <- data_list$dist11
  dist22 <- data_list$dist22
  dist12 <- data_list$dist12
  z <- data_list$sp
  y <- data_list$resp
  
  # storage
  sigma_mcmc <- matrix(NA, num_mcmc, 1)
  phi_mcmc <- matrix(NA, num_mcmc, 1)
  accept_ratio <- matrix(0, num_mcmc, 1)
  mu_mcmc <- matrix(NA, num_mcmc, 1)
  beta_mcmc <- matrix(NA, num_mcmc, p + 1)
  pred_mcmc <- matrix(NA, num_mcmc, m)
  
  # priors
  mu0 <- matrix(0, nrow = p + 1, ncol = 1)
  Sigma0 <- 10 * diag(1, p + 1, p + 1)
  Sigma0_inv <- solve(Sigma0)
  prior_prod <- Sigma0_inv %*% mu0

  # initialize
  # beta <- c(0, 1); beta_mcmc[1,] <- beta
  # sigma <- 1; sigma_mcmc[1,] <- sigma
  # sigma2 <- sigma^2
  # phi <- 3; phi_mcmc[1,] <- phi
  # phi2 <- phi^2
  # Omega <- exp(-dist11^2/(2*phi2)) + diag(delta, n, n)
  # Omega_inv <- solve(Omega)
  beta <- chol(Sigma0) %*% rnorm(p + 1) + mu0; beta_mcmc[1,] <- beta
  sigma <- invgamma::rinvgamma(1, sigma_a, sigma_b); sigma_mcmc[1,] <- sigma
  sigma2 <- sigma^2
  phi <- invgamma::rinvgamma(1, phi_a, phi_b); phi_mcmc[1,] <- phi
  phi2 <- phi^2
  Omega <- exp(-dist11^2/(2*phi2)) + diag(delta, n, n)
  Omega_inv <- solve(Omega)
  
  X_obs <- matrix(1, nrow = length(data_list$sp), ncol = 1)
  XtOX_obs <- t(X_obs) %*% Omega_inv %*% X_obs
  XtOz_obs <- t(X_obs) %*% Omega_inv %*% z

  # adaptive
  Ct <- initial_prop_var
  
  # sampler
  message(paste0("Beginning sampling at "), Sys.time())
  pb <- txtProgressBar(min = 0, max = num_mcmc, style = 3, width = 50, char = "=")
  for(iter in 2:num_mcmc){
    # mu
    V_obs <- solve(1/sigma2 * XtOX_obs + 1/100) + diag(delta, p, p)
    m_obs <- V_obs %*% (1/sigma2 * XtOz_obs)
    mu <- c(chol(V_obs) %*% rnorm(1) + m_obs)
    
    # sigma
    a <- sigma_a + n/2
    b <- c(sigma_b + .5 * t(z - mu) %*% Omega_inv %*% (z - mu))
    sigma <- sqrt(invgamma::rinvgamma(1, a, b))
    sigma2 <- sigma^2
    
    # phi - metropolis
    ## adaptive
    if(adapt){
      if(iter <= adapt_period){
        Ct <- initial_prop_var
      } else if(iter > adapt_period){
        Ct <- sd * cov(phi_mcmc[1:(iter-1),,drop = F]) + sd * epsilon
      }
    }
    
    ## proposal
    phi_s <- -1
    while(phi_s <= 0) phi_s <- phi + rnorm(1, 0, sqrt(Ct))
    phi2_s <- phi_s^2
    Omega_s <- exp(-dist11^2/(2*phi2_s)) + diag(delta, n, n)

    ## evaluate proposal
    log_post_current <- mvtnorm::dmvnorm(z, rep(mu,n), sigma2 * Omega, log = T) + invgamma::dinvgamma(phi, phi_a, phi_b, log = T)
    log_post_s <- mvtnorm::dmvnorm(z, rep(mu,n), sigma2 * Omega_s, log = T) + invgamma::dinvgamma(phi_s, phi_a, phi_b, log = T)
    log_r <- log_post_s - log_post_current
    if(log(runif(1)) < log_r){
      phi <- phi_s
      phi2 <- phi_s^2
      Omega <- exp(-dist11^2/(2*phi2)) + diag(delta, n, n)
      Omega_inv <- solve(Omega)
      XtOX_obs <- t(X_obs) %*% Omega_inv %*% X_obs
      XtOz_obs <- t(X_obs) %*% Omega_inv %*% z

      accept_ratio[iter,] <- 1
    }
    
    # predict
    Sigma11_inv <- (1/sigma^2) * Omega_inv
    Sigma12 <- sigma^2 * exp(-dist12^2 / (2*phi2))
    Sigma22 <- sigma^2 * exp(-dist22^2 / (2*phi2))
    
    t.Sigma11_inv.Sigma12 <- t(Sigma11_inv %*% Sigma12)
    Sigma2.1 <- Sigma22 - t.Sigma11_inv.Sigma12 %*% Sigma12
    Sigma2.1[lower.tri(Sigma2.1)] = t(Sigma2.1)[lower.tri(Sigma2.1)]
    mu2.1 <- t.Sigma11_inv.Sigma12 %*% (matrix(c(z) - c(mu), ncol = 1))
    eta <- mvtnorm::rmvnorm(1, mu2.1, Sigma2.1 + diag(delta, dim(Sigma2.1)))

    # betas
    pred <- data_list$z_atobsy
    pred[which(is.na(pred))] <- c(eta)
    model_mat <- cbind(
      X_, 
      pred
    )
    
    ## assume variance is known and 1
    V_beta <- solve(t(model_mat) %*% model_mat + Sigma0_inv)
    m_beta <- V_beta %*% (t(model_mat) %*% y + prior_prod)
    beta <- chol(V_beta + diag(delta, dim(V_beta))) %*% rnorm(p+1) + m_beta
    
    # storage
    beta_mcmc[iter,] <- c(beta)
    sigma_mcmc[iter,] <- sigma
    phi_mcmc[iter,] <- phi
    mu_mcmc[iter,] <- mu
    pred_mcmc[iter,] <- c(eta)

    # progress
    setTxtProgressBar(pb, iter)
  }
  close(pb)
  message(paste0("Ending sampling at "), Sys.time())
  
  samples <- cbind(
    beta_mcmc[(warmup+1):num_mcmc,],
    sigma_mcmc[(warmup+1):num_mcmc,],
    phi_mcmc[(warmup+1):num_mcmc,],
    mu_mcmc[(warmup+1):num_mcmc,],
    pred_mcmc[(warmup+1):num_mcmc,]
  )
  
  colnames(samples) <- c(
    paste0(rep("beta[", p+1), 1:(p+1), rep("]", p+1)), 
    "sigma", 
    "phi",
    "mu",
    paste0(rep("pred[", m), 1:(m), rep("]", m))
  )
  
  return(
    list(
      samples = samples,
      accept_ratio = accept_ratio
    )
  )
  
}

# parallel
this_cluster <- makeCluster(3)
samples <- parLapply(
  cl = this_cluster,
  X = 1:3,
  fun = latentgp_mhgibbs_predict,
  num_mcmc = 10000,
  warmup = 5000,
  data_list = data_list,
  X_ = cbind(
    rep(1, length(data_list$resp))
  ),
  phi_a = 4,
  phi_b = 11.2,
  sigma_a = 1,
  sigma_b = 1,
  initial_prop_var = .075^2,
  adapt = TRUE,
  delta = 1e-06
)
stopCluster(this_cluster)
```

```{r}
colMeans(samples[[1]]$accept_ratio)
nimble_summary(list(samples[[1]]$samples, samples[[2]]$samples, samples[[3]]$samples), warmup = 0)
```

### Simulation with synthetic data - no colocated spatial and response data

```{r, eval = F}
library(parallel)
latentgp_sim_predict <- function(nsims, n = 100){
  sum_tbl <- list()
  pb <- txtProgressBar(min = 0, max = nsims, style = 3, width = 50, char = "=")
  for(sim in 1:nsims){
    # simulate data
    sim_dat <- sim_latentgp_predict(
      n = 10^2, 
      sigma = 1, 
      phi = 3, 
      seed = sim, 
      delta = 1e-6, 
      colocate = "none"
    )
    data_list <- data_prep(
      sim_dat$df
    )
    
    # fit model - parallel
    tmp_sim <- sim
    this_cluster <- makeCluster(3)
    samples <- parLapply(
      cl = this_cluster,
      X = 1:3,
      fun = latentgp_mhgibbs_predict,
      num_mcmc = 10000,
      warmup = 5000,
      data_list = data_list,
      X_ = cbind(
        rep(1, length(data_list$resp))
      ),
      phi_a = 4,
      phi_b = 11.2,
      sigma_a = 1,
      sigma_b = 1,
      initial_prop_var = .075^2,
      adapt = TRUE,
      delta = 1e-06
    )
    stopCluster(this_cluster)
    
    sum <- nimble_summary(
      list(samples[[1]]$samples, samples[[2]]$samples, samples[[3]]$samples), 
      warmup = 0
    )
    sum_tbl[[sim]] <- tibble(
      param = rownames(sum),
      truth = c(
        0, 1, 1, 3, 0,
        data_list$data %>% filter(is.na(obs_z)) %>% select(z) %>% unlist %>% unname
      ),
      mean = sum[,1],
      lwr = sum[,5],
      upr = sum[,9],
      rhat = sum[,10],
      ess_bulk = sum[,11],
      ess_tail = sum[,12]
    ) %>%
      mutate(sim = tmp_sim)
    
    setTxtProgressBar(pb, sim)
  }
  close(pb)
  
  return(do.call("bind_rows", sum_tbl))
}
latentgp_sims_predict <- latentgp_sim_predict(100, 100)
saveRDS(latentgp_sims_predict, "rds files/latentgp_sims_predict_1_3.rds")
```

```{r}
latentgp_sims <- readRDS("rds files/latentgp_sims_predict_1_3.rds")
latentgp_sims %>%
  filter(!grepl("pred[[]", param)) %>%
  mutate(
    capture = factor(case_when(
      truth >= lwr & truth <= upr ~ 1, 
      TRUE ~ 0
    ))
  ) %>%
  ggplot() + 
  geom_linerange(
    aes(xmin = lwr, xmax = upr, x = mean, col = capture, y = sim)
  ) +
  facet_wrap(~ param, scales = "free_x") +
  theme_bw()

latentgp_sims %>%
  filter(grepl("pred[[]", param)) %>%
  mutate(
    capture = factor(case_when(
      truth >= lwr & truth <= upr ~ 1, 
      TRUE ~ 0
    ))
  ) %>%
  mutate(param = factor(param, levels = gtools::mixedsort(unique(.data$param)))) %>%
  ggplot() + 
  geom_linerange(
    aes(xmin = lwr, xmax = upr, x = mean, col = capture, y = sim)
  ) +
  facet_wrap(~ param, scales = "free_x") +
  theme_bw()
```

\newpage

# References


